<!doctype html>
<html>
  <head>
    <title>PANG!</title>
    <link rel="shortcut icon" href="../favicon.ico">
    <link rel="icon" href="../favicon.ico">
    <meta charset="utf-8">
    <link rel="stylesheet" href="../style.css">
  </head>

  <body>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: { inlineMath: [['$', '$']], displayMath: [['$$', '$$']] }
    });
</script>
<script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
    <center>
      "이제 나는 <a href="../index.html"><em>어떠한 저항도 하지 않기로</em></a> 결심했다."
      <br>
      1914년 8월 26일, 비트겐슈타인
    <hr width="50%" noshade>
    <a href="../me.html">Me/나</a>
    &nbsp;
    <a href="../trans.html">Translation/번역</a>
    &nbsp;
    <a href="../journal.html">Journal/일기</a>
    &nbsp;
    <a href="../study.html">Study/공부</a>
    <hr width="70%" noshade>
  </center>
<h1>P와 NP, 그 동지들</h1>
<center>스콧 애론슨</center>

<p>복잡도에 대해 본격적으로 얘기하려면 점근 표기법(asymplotics, asymptotic notation)을 잘 다뤄야 한다고 배웠다. 점근 표기법은 어떤 문제를 10,000 스텝 만에 풀 수 있다는 식으로 표현하지 않고, 문제에 대한 인스턴스 $n$개가 무한히 증가할 때 $cn^2$ 스텝 안에 풀 수 있다는 식으로 표현한다. 5장에서 설명했듯이 $TIME(f(n))$은 $O(f(n))$ 스텝 만에 풀 수 있는 모든 문제의 집합이고, $SPACE(f(n))$은 $O(f(n))$ 비트의 메모리로 풀 수 있는 모든 문제의 집합이다.</p>

<p>하지만 복잡도 이론을 본격적으로 다루려면 이보다 거시적인 관점으로 보면 좋다. 다시 말해 $O(n^2)$ 시간과 $O(n^3)$ 시간 사이가 아니라 다항 시간(polynomial time)과 지수 시간(exponential time)의 차이를 비교하는 것이다. 이렇게 시야를 넓히면 복잡도가 다항 시간이면 ‘빠르고’, 복잡도가 지수 시간이면 ‘느리다고’ 말할 수 있다.</p>

<p>물론 이런 관점에 대해 얼마든지 반론을 제기할 수 있다. 가령 다항 시간에 풀 수 있더라도 다항식이 $n^50000$이고, 지수 시간에 풀 수 있더라도 지수식이 $1.00000001^n$이라면 전자가 빠르고 후자가 느리다고 말할 수 없다고 말이다. 이에 대해 현실적인 관점에서 답하면 실제로 그런 경우를 자주 볼 수 있다면 방금 살펴본 추상화 방식에 분명 문제가 있겠지만 아직까지 그런 경우가 없다고 말할 수 있다. 다항 시간에 풀 수 있다고 알려진 대표적인 문제(매칭(matching, 선형 프로그래밍(linear programming), 소수 검사(primality testing)) 중에서 대부분은 실제로 실행할 만한 수준의 알고리즘이 있다. 그리고 지수 시간에 풀 수 있다고 알려진 대표적인 문제(정리 증명(theorem proving, 회로 최소화(circuit minimization) 등) 중에서 실제로 대다수는 실제로 실행할 만한 수준의 알고리즘이 없다. 결국 앞에서 말한 거시적인 관점은 경험에 토대를 두고 있는 셈이다.</p>

<p>물론 이 관점이 맞는 이유에 대해 다항 시간 알고리즘 중 $n^2$나 $n^3$ 시간이 걸리는 알고리즘이 대부분이고, $n^10000$ 시간이 걸리는 알고리즘은 거의 없는 이유가 뭔지 궁금한 사람이 분명 있을 것이다. 여기에 대한 내 답변은 전산학뿐 아니라 물리학, 화학, 경제학, 공학을 비롯해 그동안 내가 접한 양을 다루는 그 어떤 분야에서도 이러한 사례를 쉽게 찾을 수 있을 정도로 일반적인 현상이라는 것이다. 즉, 어떤 양의 단위로 표현된 $m$이 또 다른 단위로 표현된 $n$에 대해 어떤 상수 $c$의 지수승으로 증가하는 경우($m~n^c$)를 생각해보자. 이때 $c$가 구체적으로 뭔지는 모른다고 가정한다. 이것 말고는 알려진 사실이 없다면 $c$가 $2$나 $3$일 확률이 높을까? 아니면 $10000$이나 구골(googol, $10^100$)일 확률이 높을까? 지금껏 현실에서 경험한 바에 따르면 $10000$일 때보다 $2$나 $3$일 확률이 훨씬 높다. 그 이유를 정확히 설명할 수는 없다(명확히 증명할 수 있다면 정말 좋겠다). 반대로 보면 그리 놀라운 사실은 아니다. 즉, 현실에서 얼마든지 볼 수 있는 메커니즘 중에서 $n^2$에 비례해 증가하는 사례는 어렵지 않게 찾을 수 있다. 가령 $n$개의 점을 다른 점과 하나씩 비교하거나 한 변의 길이가 $n$인 정사각형의 면적을 알아내는 경우가 그런 사례다. 좀 더 머리를 굴려보면 현실에서 볼 수 있는 메커니즘 중에서 $n^3$이나 $n^4$에 비례해 증가하는 사례도 (단 몇 개라도) 찾을 수 있다. 그렇다면 $n^10000$에 비례해 증가하는 메커니즘 중에서 현실에서 볼 수 있는 예가 있을까? 임의의 상수 $k$에 대해 단순히 $n^k$에 비례하는 것 말고 더 있을까? 별로 없다. 지가 $10000$인 경우보다는 $2$나 $3$인 경우가 훨씬 많다.</p>

  </body>
</html>
